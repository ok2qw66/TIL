# Working with AWS SQS Standard Queues

### SQS → AWS에서 가장 먼저 생긴 리소스

#### 메시지(message) 

- XML, JSON과 같은 형태를 가진 데이터 
- 256KB 
- 유니코드 사용이 가능

#### 큐(queue)

- 메시지를 담는 공간
- 리전 별로 생성해야 함
- 큐 이름은 모든 리전에서 유일해야 함



#### 배치 API 

- 용량이 작은 메시지를 자주 처리하면 과금이 발생하므로 메시지를 모아서 동시에 처리



#### Visibility Timeout

- 메시지를 받은 뒤 특정 시간 동안 다른 곳에서 메시지를 볼 수 없도록 하는 기능

- 여러 서버가 메시지를 처리하는 경우 동일한 메시지를 동시에(중복해서) 처리하는 것을 방지
  - Message Available ⇒ Visible ⇒ 메시지를 꺼내 볼 수 있는 메시지
  - Message in Fight ⇒ Not Visible ⇒ 다른 곳에서 메시지를 보고 있어 볼 수 없는 메시지



#### Delay Delivery

- 특정 시간 동안 메시지를 받지 못하게 하는 기능
- Message in Fight 상태



#### Dead Letter Queues

- 일반적으로 메시지를 받아서 처리하면 메시지를 삭제
- 삭제되지 않고 남아 있는 경우에는 처리 실패 큐(Dead Letter Queues)로 보냄
- 일반 큐와 동일한 리전에 있어야 한다



#### Long Polling

- 메시지가 있으면 바로 가져오고, 없으면 올 때까지 기다림
- 1초~20초까지 기다리는 시간 설정 가능(기본 20초)



#### Short Polling

- 메시지가 있으면 바로 가져오고, 없으면 빠져나옴
- ReceiveMessage 요청에서 WaitTimeSeconds를 0으로 설정
- Queue 설정에서 ReceivedMessageWaitTimeSeconds를 0으로 설정

![2](https://user-images.githubusercontent.com/69428620/95434277-05a98800-098c-11eb-9967-f00743579628.PNG)

Boto3 SDK를 이용해서 파이썬 프로그램을 제공

SSH 터미널을 5개 실행해서 아래의 메시지 상태를 관찰

ApproximateNumberOfMessagesNotVisible	

ApproximateNumberOfMessages

ApproximateNumberOfMessagesDelayed
홈디렉터리에 있는 py 파일의 내용을 이해



- ApproximateNumberOfMessages – Returns the approximate number of messages available for retrieval from the queue.
- ApproximateNumberOfMessagesDelayed – Returns the approximate number of messages in the queue that are delayed and not available for reading immediately. This can happen when the queue is configured as a delay queue or when a message has been sent with a delay parameter.
- ApproximateNumberOfMessagesNotVisible – Returns the approximate number of messages that are in flight. Messages are considered to be *in flight* if they have been sent to a client but have not yet been deleted or have not yet reached the end of their visibility window.



## Introduction

In this hands-on lab, you will learn how to create and interact with SQS standard queues. You will send messages to an SQS queue that you create, and learn how to take advantage of SQS queues to use multiple SQS consumers to process queue data at the same time! By the end of this AWS learning activity, you should feel comfortable interacting with the SQS service via the Boto3 SDK for Python. You will also gain an understanding of how to send messages to standard queues, set queue attributes, and consume messages from the queues we create.

## Solution

Open five terminal windows and log in to the provided public instance on the lab page via SSH:

```bash
ssh cloud_user@<PUBLIC_IP_ADDRESS>
```

We'll be using each of them at the same time, so you'll want to make sure you know which is which. It could help to change the background color on each window so you can easily tell them apart.

### Create a Standard SQS Queue (*First Terminal*)

1. In one of the windows, create a queue using the Python script:

   ```
   python3 create_queue.py
   ```

2. When the command finishes, we'll see the URL of our queue (e.g., *https://queue.amazonaws.com/xxxxxxxxxxxx/mynewq*). Copy that URL.

   https://queue.amazonaws.com/136273509443/mynewq

3. Open the `sqs_url.py` file:

   ```
   vim sqs_url.py
   ```

4. Update the file so it includes the URL you just copied:

   ```
   QUEUE_URL = 'https://queue.amazonaws.com/xxxxxxxxxxxx/mynewq'
   ```

   Save and quit the file by hitting **Escape** and entering `wq!`.

5. View the contents of the file to make sure it's updated:

   ```
   cat sqs_url.py
   ```

### Monitor the Queue (*Second Terminal*)

1. In another terminal window, run a script that will keep track of what's going on in our queue:

   ```
   python3 queue_status.py
   ```

   That will check on messages in our queue, so leave it running in that window. You may want to make this window smaller than the others to keep it out of the way while still keeping an eye on it.

### Send Data (*Third Terminal*)

1. In a third terminal, run aa script that will start pushing data to the queue:

   ```
   python3 slow_producer.py
   ```

   We'll see a lot of information start to appear. After a few seconds, we'll also see the second/monitoring terminal window change, with the numbers starting to increase for the different kinds of messages.

2. Once the `slow_producer` script stops running (it will take a few minutes, and we should have 50 messages total), run the following script in the third terminal:

   ```
   python3 fast_producer.py
   ```

   The difference between the `slow_producer` and `fast_producer` is the time they wait between sending messages: Slow waits 10 seconds, and fast only waits one second.

   We'll end up with 100 messages total once it finishes running (it will take about a minute).

### Receive Messages and Extract Metadata (*Fourth and Fifth Terminals*)

1. In the fourth terminal window, run a script that will receive messages from the queue and extract some metadata from them:

   ```
   python3 fast_consumer.py
   ```

   We'll see lots of data start flowing in the fourth terminal. We'll also see, in the monitoring terminal window, that the number next to *ApproximateNumberOfMessages* starts dropping.

2. No need to wait this time — in the fifth terminal, run the following:

   ```
   python3 slow_consumer.py
   ```

   This is just a slower version of the `fast_consumer` script (as evidenced by its name).

3. Keep an eye on the monitoring terminal window — we'll see the number of *ApproximateNumberOfMessages* continue to drop. We now have *two* scripts running that are both snagging messages out of the queue, extracting data, and deleting them.

### Clean Up (*Any Terminal*)

1. We don't need to wait for the previous two scripts to finish. To cancel the processes, hit **Ctrl**+**C** in the monitoring window as well as the fourth and fifth terminal windows.

2. Run the following in any terminal window to remove all the messages from the queue:

   ```
   python3 purge_queue.py
   ```

### Run Everything at Once (*All Terminals*)

1. Keep the monitoring terminal window there to keep an eye on it while running all the scripts. (If you need to re-run the command again, it's `python3 queue_status.py`.)

2. In the next terminal, run:

   ```
   python3 slow_producer.py
   ```

3. In the next terminal, run:

   ```
   python3 slow_consumer.py
   ```

4. In the next terminal, run:

   ```
   python3 fast_consumer.py
   ```

   Watch the monitoring terminal window — the number of messages should start going down.

5. In the next terminal, run:

   ```
   python3 fast_producer.py
   ```

   In the first/monitoring terminal, we should see the number of messages start going back up again. This will continue until the producer scripts run out of data to read and the consumer scripts have processed all the messages.

   Eventually, the monitoring terminal window's three rows will all have zero counts.

## Conclusion

Congratulations on successfully completing this hands-on lab!



- create_queue.py

```
import boto3

# Create SQS client
sqs = boto3.client('sqs')

# Create a SQS queue
response = sqs.create_queue(
    QueueName='mynewq',
    Attributes={
        'DelaySeconds': '5',
        'MessageRetentionPeriod': '86400'
    }
)

print(response['QueueUrl'])
```



- queue_status.py

```
import boto3
import time
from sqs_url import QUEUE_URL

sqs = boto3.client('sqs')

i = 0

while i < 100000:
    i = i + 1
    time.sleep(1)
    response = sqs.get_queue_attributes(
        QueueUrl=QUEUE_URL,
        AttributeNames=[
            'ApproximateNumberOfMessages',
            'ApproximateNumberOfMessagesNotVisible',
            'ApproximateNumberOfMessagesDelayed',
        ]
    )
    for attribute in response['Attributes']:
        print(
            response['Attributes'][attribute] +
            ' ' +
            attribute
        )
    print('')
    print('')
    print('')
    print('')
```



- purge_queue.py

```
import boto3
from sqs_url import QUEUE_URL

sqs = boto3.client('sqs')

response = sqs.purge_queue(
    QueueUrl=QUEUE_URL
)
```





- fast_data.json

```
[
  {
    "name": "Harper Pierce",
    "email": "harperpierce@thepenguinconsultingfirm.com",
    "donation": 97.5
  },
  {
    "name": "Lois Huber",
    "email": "loishuber@thepenguinconsultingfirm.com",
    "donation": 28.31
  },
  {
    "name": "Cecile Hickman",
    "email": "cecilehickman@thepenguinconsultingfirm.com",
    "donation": 1.34
  }
]
```



- fast_producer.py

```
import boto3
import json
import time
from sqs_url import QUEUE_URL

# Create SQS client
sqs = boto3.client('sqs')

with open('fast_data.json', 'r') as f:
    data = json.loads(f.read())

for i in data:
    msg_body = json.dumps(i)
    response = sqs.send_message(
        QueueUrl=QUEUE_URL,
        MessageBody=msg_body,
        DelaySeconds=2,
        MessageAttributes={
            'JobType': {
                'DataType': 'String',
                'StringValue': 'NewDonor'
            },
            'Producer': {
                'DataType': 'String',
                'StringValue': 'Fast'
            }
        }
    )
    print('Added a message with 1 second delay - FAST')
    print(response)
    time.sleep(1)
```

- slow_producer.py

```
import boto3
import json
import time
from sqs_url import QUEUE_URL

# Create SQS client
sqs = boto3.client('sqs')

with open('slow_data.json', 'r') as f:
    data = json.loads(f.read())

for i in data:
    msg_body = json.dumps(i)
    response = sqs.send_message(
        QueueUrl=QUEUE_URL,
        MessageBody=msg_body,
        DelaySeconds=10,
        MessageAttributes={
            'JobType': {
                'DataType': 'String',
                'StringValue': 'NewDonor'
            },
            'Producer': {
                'DataType': 'String',
                'StringValue': 'Slow'
            }
        }
    )
    print('Added a message with 10 second delay - SLOW')
    print(response)
    time.sleep(1)
```



- fast_consumer.py

```
import boto3
import json
import time
from sqs_url import QUEUE_URL

# Create SQS client
sqs = boto3.client('sqs')

i = 0

while i < 10000:
    i = i + 1
    rec_res = sqs.receive_message(
        QueueUrl=QUEUE_URL,
        MessageAttributeNames=[
            'All',
        ],
        MaxNumberOfMessages=1,
        VisibilityTimeout=5,
        WaitTimeSeconds=10
    )
    del_res = sqs.delete_message(
        QueueUrl=QUEUE_URL,
        ReceiptHandle=rec_res['Messages'][0]['ReceiptHandle']
    )
    print("RECIEVED MESSAGE (FAST CONSUMER):")
    print('FROM PRODUCER: ' + rec_res['Messages'][0]['MessageAttributes']['Producer']['StringValue'])
    print('JOB TYPE: ' + rec_res['Messages'][0]['MessageAttributes']['JobType']['StringValue'])
    print('BODY: ' + rec_res['Messages'][0]['Body'])
    print("DELETED MESSAGE (FAST CONSUMER)")
    print("")
    time.sleep(2)
```



- slow_consumer.py

```
import boto3
import json
import time
from sqs_url import QUEUE_URL

# Create SQS client
sqs = boto3.client('sqs')

i = 0

while i < 10000:
    i = i + 1
    rec_res = sqs.receive_message(
        QueueUrl=QUEUE_URL,
        MessageAttributeNames=[
            'All',
        ],
        MaxNumberOfMessages=1,
        VisibilityTimeout=20,
        WaitTimeSeconds=10
    )
    del_res = sqs.delete_message(
        QueueUrl=QUEUE_URL,
        ReceiptHandle=rec_res['Messages'][0]['ReceiptHandle']
    )
    print("RECIEVED MESSAGE (SLOW CONSUMER):")
    print('FROM PRODUCER: ' + rec_res['Messages'][0]['MessageAttributes']['Producer']['StringValue'])
    print('JOB TYPE: ' + rec_res['Messages'][0]['MessageAttributes']['JobType']['StringValue'])
    print('BODY: ' + rec_res['Messages'][0]['Body'])
    print("DELETED MESSAGE (SLOW CONSUMER)")
    print("")
    time.sleep(8)
```

